	vmware 다운로드
https://www.vmware.com/products/workstation-pro/workstation-pro-evaluation.html

	CentOS ISO 파일 다운로드
http://ftp.kaist.ac.kr/CentOS/7.8.2003/isos/x86_64/

	CentOS에 깔려있는 자바 삭제
su
rpm -qa | grep java
yum remove tzdata-java.noarch
yum remove javapackages-tools.noarch
yum remove python-javapackages.noarch
rpm -qa | grep java

	JDK 다운로드
https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html

	java 설치
cd ./다운로드
ls
tar zxvf jdk-8u261-linux-x64.tar.gz
ls
mv jdk1.8.0_261/ /usr/local/jdk

	java 환경변수 설정
vi /etc/profile
export JAVA_HOME=/usr/local/jdk
export HADOOP_HOME=/opt/hadoop
PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin

source /etc/profile
java -version

	하둡 계정 생성
useradd hadoop
passwd hadoop
hadoop
hadoop

	ssh 연결 설정
su - hadoop
ssh-keygen -t rsa
ls -al
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
cat ~/.ssh/authorized_keys
chmod 0600 ~/.ssh/authorized_keys

	하둡 설치
su
wget http://mirror.rise.ph/apache/hadoop/common/hadoop-2.9.2/hadoop-2.9.2.tar.gz
tar zxvf hadoop-2.9.2.tar.gz
ls
mkdir /opt/hadoop
mv hadoop-2.9.2/* /opt/hadoop
chown -R hadoop:hadoop /opt/hadoop/
ls /opt/hadoop

	하둡 환경변수 설정
su - hadoop
ls -al
vi .bash_profile
export JAVA_HOME=/usr/local/jdk
export PATH=$PATH:$JAVA_HOME/bin
export CLASSPATH=.:$JAVA_HOME/jre/lib:$JAVA_HOME/lib:$JAVA_HOME/lib/tools.jar
export HADOOP_HOME=/opt/hadoop
export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin

source .bash_profile
echo $JAVA_HOME
echo $HADOOP_HOME

	하둡 설정파일 수정
cd $HADOOP_HOME/etc/hadoop/

vi hadoop-env.sh
# The java implementation to use.
export JAVA_HOME=/usr/local/jdk/

vi core-site.xml
	<property>
		<name>fs.default.name</name>
		<value>hdfs://localhost:9000</value>
	</property>

vi hdfs-site.xml
	<property>
		<name>dfs.replication</name>
		<value>1</value>
	</property>
	<property>
		<name>dfs.name.dir</name>
		<value>file:///opt/hadoop/hadoopdata/namenode</value>
	</property>
	<property>
		<name>dfs.data.dir</name>
		<value>file:///opt/hadoop/hadoopdata/datanode</value>
	</property>

mkdir /opt/hadoop/hadoopdata
mkdir /opt/hadoop/hadoopdata/namenode
mkdir /opt/hadoop/hadoopdata/datanode

cp mapred-site.xml.template mapred-site.xml

vi mapred-site.xml
	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
	</property>

vi yarn-site.xml
	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
	</property>

	하둡 실행 확인
hdfs namenode -format
start-all.sh
jps

	하둡 wordcount 예제
cd $HADOOP_HOME
hadoop fs -mkdir /example
hadoop fs -copyFromLocal /opt/hadoop/README.txt /example
cd /opt/hadoop/share/hadoop/mapreduce
hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar wordcount /example/README.txt /output

hadoop fs -ls /output
hadoop fs -cat /output/part-r-00000

	hadoop 계정 sudoer로 만들기
su
visudo -f /etc/sudoers

## Allows people in group wheel to run all commands 밑에
hadoop	ALL=(ALL)	ALL

	R 설치
su - hadoop
sudo yum install epel-release
sudo yum update
sudo yum install R -y
R
q()

	R-studio 설치
cd ~
wget https://download2.rstudio.org/server/centos6/x86_64/rstudio-server-rhel-1.3.1093-x86_64.rpm
sudo yum install rstudio-server-rhel-1.3.1093-x86_64.rpm
systemctl restart rstudio-server.service
systemctl enable rstudio-server.service

http://localhost:8787

	R 예제를 위한 패키지 설치
https://github.com/RevolutionAnalytics/RHadoop/wiki/downloads

su
cd /home/kbs/다운로드
ls
mv rmr2_3.3.1.tar.gz  /home/hadoop
mv rhdfs_1.0.8.tar.gz /home/hadoop
su - hadoop
ls

sudo R CMD javareconf
sudo R
install.packages(c("Rcpp","RJSONIO","digest","functional","reshape2","stringr","plyr","caTools"))
q()
sudo R CMD INSTALL rmr2_3.3.1.tar.gz
sudo R
install.packages("rJava")
q()
sudo HADOOP_CMD=/opt/hadoop/bin/hadoop R CMD INSTALL rhdfs_1.0.8.tar.gz

	R 예제
Sys.setenv(HADOOP_CMD="/opt/hadoop/bin/hadoop")
Sys.setenv(HADOOP_STREAMING="/opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.9.2.jar")
library(rhdfs)
hdfs.init()
library(rmr2)
small.ints <- to.dfs(1:10)
map.fn <- function(k,v){
	val = cbind(v, v^2)
	return(keyval(k, val))
}
result <- mapreduce(input = small.ints, map = map.fn)
out <- from.dfs(result)
out

	spark 설치
http://spark.apache.org/downloads.html
su
cd /home/kbs/다운로드
ls
tar -xvzf spark-3.0.1-bin-hadoop2.7.tgz
mv spark-3.0.1-bin-hadoop2.7/ spark/
mv spark /home/hadoop
cd /home/hadoop
ls
su - hadoop

	spark 환경변수 설정
vi .bash_profile
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
export SPARK_HOME=/home/hadoop/spark
export PATH=$PATH:$SPARK_HOME/bin

source .bash_profile
sudo chown -R hadoop:hadoop spark
spark-shell

	anaconda 및 pyspark 설치
wget https://repo.anaconda.com/archive/Anaconda3-2020.07-Linux-x86_64.sh
bash Anaconda3-2020.07-Linux-x86_64.sh
source .bashrc
pip install pyspark

	pyspark 예제
jps
jupyter notebook
hadoop fs -copyFromLocal /home/hadoop/spark/LICENSE /example
hadoop fs -ls /example

import pyspark
from pyspark import SparkContext
sc = SparkContext()
licLines = sc.textFile("/example/LICENSE")
linecnt = licLines.count()
linecnt

	하둡 종료 후 확인
stop-all.sh
jps